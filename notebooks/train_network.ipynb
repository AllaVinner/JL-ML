{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "196293e968144f5642c1d9ffee4d471cc2edffa0ebaedde3b86b762e71f62b8a"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('jenv': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "train_network.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7t6_lUj0vqc"
      },
      "source": [
        "# Train autoencoder\n",
        "This notebook is made to train an autoencoder or a variational autoencoder on the mnist data set. It can be run locally or on golab. Checks have been implemented for colab use. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28pudOgz0vqk"
      },
      "source": [
        "## Check if in Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-b2sIj60vql",
        "outputId": "6730b13f-fbc1-4f84-eabd-3c7cb663bd3e"
      },
      "source": [
        "import os\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "print(\"Is in Colab: \", IN_COLAB)\n",
        "if IN_COLAB:\n",
        "    os.system('git clone https://github.com/AllaVinner/JL-ML.git')\n",
        "    os.system('pip install -e JL-ML')\n",
        "    import site\n",
        "    site.main()\n",
        "    \n",
        "saved_path   = os.path.join('..','saved-models') if not IN_COLAB else os.path.join('JL-ML','saved-models')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is in Colab:  False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xg0Y8ZVv0vqo"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEJ15tay0vqp"
      },
      "source": [
        "#Test to load\n",
        "import yaml\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "from jlauto.models.variational_autoencoder import VariationalAutoencoder\n",
        "from jlauto.models.autoencoder import Autoencoder\n",
        "from jlauto.models.load_premade import load_premade_model\n",
        "from jlauto.models.continuous_bernoulli_loss import continuous_bernoulli_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gTDLEsd0vqp"
      },
      "source": [
        "#Preprocess mnist data\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "#num_samples = 100\n",
        "train_digits = np.expand_dims(x_train, -1).astype(\"float32\") / 255\n",
        "input_shape = train_digits.shape[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvX14kT-0vqq"
      },
      "source": [
        "# Set default configure \n",
        "config = {\n",
        "    'name': 'CHANGE',\n",
        "    'model_type': 'autoencoder',\n",
        "    'model_name': 'mnist_cnn_shallow',\n",
        "    'latent_dim': 'CHANGE',\n",
        "    'optimizer': 'adam',\n",
        "    'loss': 'binary_crossentropy', \n",
        "    'batch_size': 512,\n",
        "    'epochs': 1,\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bh_KhjaU0vqr"
      },
      "source": [
        "# Changing parameters\n",
        "changing_config = {}\n",
        "changing_config['latent_dim'] = [3,4]\n",
        "changing_config['name']   = ['ae_latent_dim_'+str(lat_dim) for lat_dim in changing_config['latent_dim']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2_BrvQm0vqs"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnsJLLjC0vqs",
        "outputId": "2fb5c715-0152-4385-a4b2-1bb2ab95083c"
      },
      "source": [
        "for i in range(len(changing_config['name'])):\n",
        "  # update config\n",
        "  for key, values in changing_config.items():\n",
        "    config[key] = values[i]\n",
        "  \n",
        "  # Save config\n",
        "  model_path = os.path.join(saved_path,config['name'])\n",
        "  os.system(f'mkdir {model_path}')\n",
        "  with open(os.path.join(saved_path,config['name'],'config.yaml'), 'w') as yaml_file:\n",
        "    yaml.dump(config, yaml_file)\n",
        "\n",
        "  # Create and train model\n",
        "  model = load_premade_model(model_type = config['model_type'],\n",
        "                            model_name = config['model_name'],\n",
        "                            input_shape = input_shape,\n",
        "                            latent_dim = config['latent_dim'])\n",
        "\n",
        "  model.compile(optimizer = config['optimizer'],loss = config['loss'])\n",
        "\n",
        "  model.fit(train_digits,train_digits,\n",
        "            epochs = config['epochs'],\n",
        "            batch_size = config['batch_size'])\n",
        "\n",
        "  model.save(os.path.join(saved_path, config['name']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "118/118 [==============================] - 43s 341ms/step - loss: 0.3422\n",
            "INFO:tensorflow:Assets written to: ..\\saved-models\\ae_latent_dim_3\\assets\n",
            "(28, 28, 1)\n",
            "118/118 [==============================] - 41s 326ms/step - loss: 0.3464\n",
            "INFO:tensorflow:Assets written to: ..\\saved-models\\ae_latent_dim_4\\assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZNeZi_20vqt"
      },
      "source": [
        "## Zip if in colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6IVuZAj0vqu"
      },
      "source": [
        "# zip each file individually\n",
        "if IN_COLAB:\n",
        "    for i,name in enumerate(changing_config['name']):\n",
        "        os.system(f'zip -r ./model_{i}.zip {os.path.join(saved_path,name)}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvBb_Mzy0vqu"
      },
      "source": [
        "# Investigate model"
      ]
    }
  ]
}