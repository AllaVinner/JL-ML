{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test implementation of a Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow import keras\r\n",
    "from keras import layers, losses\r\n",
    "\r\n",
    "from keras.datasets import mnist\r\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, y_test) = mnist.load_data()\r\n",
    "\r\n",
    "def preprocess_images(images, discrete=True):\r\n",
    "    # Normalize and make into tensor\r\n",
    "    images = images.reshape((images.shape[0], 28, 28, 1)) /255.\r\n",
    "\r\n",
    "    if discrete:\r\n",
    "        # Round pixel values to 0 or 1. Allows use of cross entropy loss?\r\n",
    "        return np.where(images > .5, 1.0, 0.0).astype('float32')\r\n",
    "    else:\r\n",
    "        # No discretization of pixel values\r\n",
    "        return images.astype('float32')\r\n",
    "\r\n",
    "# Look at random image (before binarization)\r\n",
    "img_nbr = np.random.randint(0, len(x_train)+1)\r\n",
    "plt.imshow(x_train[img_nbr, :, :])\r\n",
    "plt.show()\r\n",
    "\r\n",
    "x_train = preprocess_images(x_train) # shape: (nbr_images, 28, 28, 1)\r\n",
    "x_test = preprocess_images(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we need to batch and shuffle the data?\r\n",
    "# Maybe in we dont use the fit() function, we need to do it manually\r\n",
    "\r\n",
    "train_size = x_train.shape[0]\r\n",
    "batch_size = 32 # Size of batches in gradient update / training step?\r\n",
    "test_size = x_test.shape[0]\r\n",
    "print(x_test.shape)\r\n",
    "\r\n",
    "train_dataset = (tf.data.Dataset.from_tensor_slices(x_train).shuffle(train_size).batch(batch_size))\r\n",
    "test_dataset = (tf.data.Dataset.from_tensor_slices(x_test).shuffle(test_size).batch(batch_size))\r\n",
    "\r\n",
    "tf.print(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative functional approach\n",
    "\n",
    "https://keras.io/examples/generative/vae/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\r\n",
    "# https://www.tensorflow.org/tutorials/generative/cvae\r\n",
    "\r\n",
    "class VAE(Model):\r\n",
    "    def __init__(self, latent_dim=2):\r\n",
    "        super(VAE, self).__init__()\r\n",
    "        self.latent_dim = latent_dim\r\n",
    "\r\n",
    "        self.encoder = keras.Sequential([\r\n",
    "            layers.InputLayer(input_shape=(28, 28, 1)),\r\n",
    "\r\n",
    "            layers.Conv2D(\r\n",
    "                filters=32, kernel_size=3, strides=(2, 2), activation='relu'),\r\n",
    "            layers.Conv2D(\r\n",
    "                filters=64, kernel_size=3, strides=(2, 2), activation='relu'),\r\n",
    "            layers.Flatten(),\r\n",
    "\r\n",
    "            # 2D latent space -> 2D mean, 2D var ->\r\n",
    "            # mean1, mean2, log_var1, log_var2 -> 2 + 2\r\n",
    "            layers.Dense(latent_dim + latent_dim),\r\n",
    "        ])\r\n",
    "\r\n",
    "        self.decoder = keras.Sequential([\r\n",
    "            # Point z sampled from distrs. will be 2D\r\n",
    "            layers.InputLayer(input_shape=(latent_dim,)),\r\n",
    "\r\n",
    "            # BIG dense that takes 2d z input\r\n",
    "            layers.Dense(units=7*7*32, activation='relu'),\r\n",
    "\r\n",
    "            # Reshape into tensor\r\n",
    "            layers.Reshape(target_shape=(7, 7, 32)),\r\n",
    "\r\n",
    "            # Transp. Conv: padding same? no upsampling?\r\n",
    "            # Pads the input so output is same dim?\r\n",
    "            layers.Conv2DTranspose(\r\n",
    "                filters=64, kernel_size=3, strides=(2, 2), padding='same',\r\n",
    "                activation='relu'),\r\n",
    "            layers.Conv2DTranspose(\r\n",
    "                filters=32, kernel_size=3, strides=(2, 2), padding='same',\r\n",
    "                activation='relu'),\r\n",
    "\r\n",
    "            # Last layer, no activation / linear?\r\n",
    "            layers.Conv2DTranspose(\r\n",
    "                filters=1, kernel_size=3, strides=(1, 1), padding='same'),\r\n",
    "        ])\r\n",
    "\r\n",
    "    # Decorator: turns py code into graph\r\n",
    "    # Use for computationally expensive functions\r\n",
    "    @tf.function\r\n",
    "    def sample(self, eps=None):\r\n",
    "        # Sample 100 random z?\r\n",
    "        if eps is None:\r\n",
    "            eps = tf.random.normal(shape=(100, self.latent_dim))\r\n",
    "        return self.decode(eps, apply_sigmoid=True)\r\n",
    "    \r\n",
    "    def encode(self, x):\r\n",
    "        mean, logvar = tf.split(\r\n",
    "            self.encoder(x), num_or_size_splits=2, axis=1)\r\n",
    "        return mean, logvar\r\n",
    "\r\n",
    "    def reparameterize(self, mean, logvar):\r\n",
    "        # Returns a z sampled from N(mean, var)\r\n",
    "        \r\n",
    "        # Added stuff to deal with batches?\r\n",
    "        batch = tf.shape(mean)[0]\r\n",
    "        dim = tf.shape(mean)[1]\r\n",
    "        \r\n",
    "        \r\n",
    "        eps = tf.random.normal(shape=(batch, dim))\r\n",
    "        return mean + eps * tf.exp(logvar * .5) # mu + eps * std\r\n",
    "\r\n",
    "    def decode(self, z, apply_sigmoid=False):\r\n",
    "        # Decode latent z into image\r\n",
    "        # apply_sigmoid: outputs pixel values [0, 1]\r\n",
    "        logits = self.decoder(z) # logits vals: (-inf, inf)?\r\n",
    "        if apply_sigmoid:\r\n",
    "            probs = tf.sigmoid(logits)\r\n",
    "            return probs\r\n",
    "        return logits\r\n",
    "\r\n",
    "    # Needed for summary\r\n",
    "    def call(self, x):\r\n",
    "        mean, logvar = self.encode(x)\r\n",
    "        sampled_z = self.reparameterize(mean, logvar)\r\n",
    "        decoded_img = self.decode(sampled_z)\r\n",
    "        return decoded_img\r\n",
    "    \r\n",
    "    def summary(self):\r\n",
    "        x = keras.Input(shape=(28, 28, 1))\r\n",
    "        print(self.call(x))\r\n",
    "        model = Model(inputs=[x], outputs=self.call(x))\r\n",
    "        return model.summary()\r\n",
    "        \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_4:0\", shape=(), dtype=int32)\n",
      "Tensor(\"strided_slice_5:0\", shape=(), dtype=int32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert a partially known TensorShape to a Tensor: (None, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-7930301c2acc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-78-569a8bbc1f82>\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-569a8bbc1f82>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0msampled_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[0mdecoded_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_z\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecoded_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-569a8bbc1f82>\u001b[0m in \u001b[0;36mreparameterize\u001b[1;34m(self, mean, logvar)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0meps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmean\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0meps\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogvar\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# mu + eps * std\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\JL-ML\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\JL-ML\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_normal\u001b[1;34m(shape, mean, stddev, dtype, seed, name)\u001b[0m\n\u001b[0;32m     87\u001b[0m   \"\"\"\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random_normal\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mshape_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[0mmean_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0mstddev_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"stddev\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\JL-ML\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m   1027\u001b[0m       \u001b[1;31m# not convertible to Tensors because of mixed content.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m       \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\JL-ML\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\JL-ML\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_tensor_shape_tensor_conversion_function\u001b[1;34m(s, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    352\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    355\u001b[0m         \"Cannot convert a partially known TensorShape to a Tensor: %s\" % s)\n\u001b[0;32m    356\u001b[0m   \u001b[0ms_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot convert a partially known TensorShape to a Tensor: (None, 2)"
     ]
    }
   ],
   "source": [
    "model = VAE(2)\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining loss function\r\n",
    "\r\n",
    "# learning rate: 1e-4\r\n",
    "optimizer = tf.keras.optimizers.Adam(1e-4)\r\n",
    "\r\n",
    "# Returns logarithm of normal pdf w. \r\n",
    "# mean, logvar for each value in 'sample'\r\n",
    "def log_normal_pdf(sample, mean, logvar, raxis=1):\r\n",
    "    log2pi = tf.math.log(2. * np.pi)\r\n",
    "\r\n",
    "    # log(norm_pdf(sample; mean, var))\r\n",
    "    values = -.5 * (logvar + log2pi + \r\n",
    "    (sample - mean)**2 * tf.exp(-logvar))\r\n",
    "\r\n",
    "    # 'values' consists of log pdf in both latent x- and y-directions\r\n",
    "    # 'reduce_sum' sums these up to one value\r\n",
    "    return tf.reduce_sum(values, axis=raxis)\r\n",
    "\r\n",
    "\r\n",
    "def compute_loss(model, x):\r\n",
    "    # Compute ELBO loss w.r.t a sample x (or batch?)\r\n",
    "    mean, logvar = model.encode(x)\r\n",
    "    z = model.reparameterize(mean, logvar)\r\n",
    "    x_logit = model.decode(z)\r\n",
    "\r\n",
    "    # Loss between input & output (reconstruction). Binary cross entropy\r\n",
    "    # indep. for each pixel?\r\n",
    "    cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(\r\n",
    "        logits=x_logit, labels=x)\r\n",
    "    \r\n",
    "    log_px_z = -tf.reduce_sum(cross_ent, axis=[1,2,3])\r\n",
    "    log_pz = log_normal_pdf(z, 0., 0.)\r\n",
    "    log_qz_x = log_normal_pdf(z, mean, logvar)\r\n",
    "\r\n",
    "    # 'mean' to approx. expectation\r\n",
    "    return -tf.reduce_mean(log_px_z + log_pz - log_qz_x)\r\n",
    "\r\n",
    "\r\n",
    "@tf.function\r\n",
    "def train_step(model, x, optimizer):\r\n",
    "    # Computes gradients and updates weights\r\n",
    "\r\n",
    "    # TODO: learn how gradient tape works\r\n",
    "    with tf.GradientTape() as tape:\r\n",
    "        loss = compute_loss(model, x)\r\n",
    "    \r\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\r\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\r\n",
    "\r\n",
    "epochs = 10\r\n",
    "latent_dim = 4\r\n",
    "nbr_examples_to_generate = 16\r\n",
    "\r\n",
    "# constant random latent vector\r\n",
    "# Used for showing samples during training?\r\n",
    "random_vector_for_generation = tf.random.normal(\r\n",
    "    shape=[nbr_examples_to_generate, latent_dim])\r\n",
    "\r\n",
    "model = VAE(latent_dim)\r\n",
    "\r\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, test_dataset, test_sample=None):\r\n",
    "    # Generates and plots 16 images.\r\n",
    "    # Specify which samples though 'test_sample',\r\n",
    "    # else random are picked from dataset\r\n",
    "    \r\n",
    "    if test_sample is not None:\r\n",
    "        mean, logvar = model.encode(test_sample)\r\n",
    "    else:\r\n",
    "        # Pick 16 random images to generate\r\n",
    "        assert batch_size >= nbr_examples_to_generate\r\n",
    "\r\n",
    "        for test_batch in test_dataset.take(1): # 'take' picks a random batch\r\n",
    "            sample = test_batch[0:nbr_examples_to_generate, :, :, :] # pick 'nbr_ex..' samples\r\n",
    "            \r\n",
    "        mean, logvar = model.encode(sample)\r\n",
    "        \r\n",
    "    z = model.reparameterize(mean, logvar)\r\n",
    "    samples = model.sample(z)\r\n",
    "    fig = plt.figure(figsize=(4, 4))\r\n",
    "    \r\n",
    "    # plot sampled images\r\n",
    "    for i in range(samples.shape[0]):\r\n",
    "        plt.subplot(4, 4, i + 1)\r\n",
    "        plt.imshow(samples[i, :, :, 0])\r\n",
    "        plt.axis('off')\r\n",
    "    \r\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\r\n",
    "import time\r\n",
    "from IPython import display\r\n",
    "progbar = tf.keras.utils.Progbar(len(train_dataset))\r\n",
    "\r\n",
    "for epoch in range(1, epochs+1):\r\n",
    "    start_time = time.time()\r\n",
    "    \r\n",
    "    for i, training_batch in enumerate(train_dataset):\r\n",
    "        train_step(model, training_batch, optimizer)\r\n",
    "        progbar.update(i)\r\n",
    "        \r\n",
    "    end_time = time.time()\r\n",
    "    \r\n",
    "    loss = tf.keras.metrics.Mean()\r\n",
    "    \r\n",
    "    for test_batch in test_dataset:\r\n",
    "        loss(compute_loss(model, test_batch))\r\n",
    "    \r\n",
    "    elbo = -loss.result()\r\n",
    "    display.clear_output(wait=False)\r\n",
    "    print('Epoch {}/{}, Test ELBO: {}, time for epoch: {:.1f}s'.format(\r\n",
    "        epoch, epochs, elbo, end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_images(model, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.print('')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd593813f0e920a894f9bede9157c42ea32ce77eaa35990e17a2847ab973ef24"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('JL-ML': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}