{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from normalsamplinglayer import NormalSamplingLayer\n",
    "import numpy.random as rnd\n",
    "\n",
    "from variationalautoencoder import VariationalAutoencoder\n",
    "from autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "latent_dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data\n",
    "Load and preprocess data\n",
    "\n",
    "After this section we will have the two variables *mnist_digits* and *mnist_labels*. They are both numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "mnist_labels = np.concatenate([y_train, y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup autoencoders\n",
    "Define the encoder and decoder which are then the defining features of our variational encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the encoders and decoders. The code is simply repeated for the autoencoder and the variational autoencoder. The only difference is that there is a parallell layer in the encoder for the variational autoencoder which defindes the variacnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder encoder\n",
    "encoder_input = keras.Input(shape = mnist_digits[0].shape)\n",
    "net = encoder_input\n",
    "net = keras.layers.Conv2D(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2D(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Flatten()(net)\n",
    "net = keras.layers.Dense(16, activation = 'relu')(net)\n",
    "z = keras.layers.Dense(latent_dim, name = 'z_mean')(net)\n",
    "encoder_auto = keras.Model(encoder_input, z, name = 'encoder')\n",
    "\n",
    "# Variational autoencoder encoder\n",
    "encoder_input = keras.Input(shape = mnist_digits[0].shape)\n",
    "net = encoder_input\n",
    "net = keras.layers.Conv2D(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2D(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Flatten()(net)\n",
    "net = keras.layers.Dense(16, activation = 'relu')(net)\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(net)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(net)\n",
    "z = NormalSamplingLayer()([z_mean, z_log_var])\n",
    "encoder_var = keras.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "\n",
    "# Autoencoder decoder\n",
    "decoder_input = keras.Input(shape = (latent_dim,))\n",
    "net = decoder_input\n",
    "net = keras.layers.Dense(7*7*64, activation = \"relu\")(net)\n",
    "net = keras.layers.Reshape((7,7,64))(net)\n",
    "net = keras.layers.Conv2DTranspose(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(1,3, activation = 'sigmoid', padding = 'same')(net)\n",
    "decoder_output = net\n",
    "decoder_auto = keras.Model(decoder_input, decoder_output, name = 'decoder')\n",
    "\n",
    "# Variational autoencoder decoder\n",
    "decoder_input = keras.Input(shape = (latent_dim,))\n",
    "net = decoder_input\n",
    "net = keras.layers.Dense(7*7*64, activation = \"relu\")(net)\n",
    "net = keras.layers.Reshape((7,7,64))(net)\n",
    "net = keras.layers.Conv2DTranspose(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(1,3, activation = 'sigmoid', padding = 'same')(net)\n",
    "decoder_output = net\n",
    "decoder_var = keras.Model(decoder_input, decoder_output, name = 'decoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the autoencoder instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(encoder_auto, decoder_auto)\n",
    "va = VariationalAutoencoder(encoder_var, decoder_var)\n",
    "ae.compile(optimizer=keras.optimizers.Adam())\n",
    "va.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "274/274 [==============================] - 60s 213ms/step - Loss: 269.2907\n",
      "Epoch 2/20\n",
      "274/274 [==============================] - 67s 245ms/step - Loss: 141.2929\n",
      "Epoch 3/20\n",
      "274/274 [==============================] - 73s 268ms/step - Loss: 129.7478\n",
      "Epoch 4/20\n",
      "274/274 [==============================] - 67s 245ms/step - Loss: 125.5950\n",
      "Epoch 5/20\n",
      "274/274 [==============================] - 62s 226ms/step - Loss: 122.9442\n",
      "Epoch 6/20\n",
      "274/274 [==============================] - 67s 246ms/step - Loss: 121.6892\n",
      "Epoch 7/20\n",
      "274/274 [==============================] - 63s 230ms/step - Loss: 119.8369\n",
      "Epoch 8/20\n",
      "274/274 [==============================] - 64s 234ms/step - Loss: 118.8873\n",
      "Epoch 9/20\n",
      "274/274 [==============================] - 62s 225ms/step - Loss: 117.9139\n",
      "Epoch 10/20\n",
      "274/274 [==============================] - 68s 247ms/step - Loss: 117.1101\n",
      "Epoch 11/20\n",
      "274/274 [==============================] - 64s 232ms/step - Loss: 116.8547\n",
      "Epoch 12/20\n",
      "274/274 [==============================] - 63s 231ms/step - Loss: 116.0140\n",
      "Epoch 13/20\n",
      "274/274 [==============================] - 70s 257ms/step - Loss: 115.2773\n",
      "Epoch 14/20\n",
      "274/274 [==============================] - 62s 225ms/step - Loss: 115.0219\n",
      "Epoch 15/20\n",
      "274/274 [==============================] - 68s 248ms/step - Loss: 114.3186\n",
      "Epoch 16/20\n",
      "274/274 [==============================] - 62s 228ms/step - Loss: 114.4243\n",
      "Epoch 17/20\n",
      "274/274 [==============================] - 65s 236ms/step - Loss: 113.8808\n",
      "Epoch 18/20\n",
      "274/274 [==============================] - 67s 244ms/step - Loss: 113.6305\n",
      "Epoch 19/20\n",
      "274/274 [==============================] - 66s 242ms/step - Loss: 113.1963\n",
      "Epoch 20/20\n",
      "274/274 [==============================] - 61s 221ms/step - Loss: 113.0182\n",
      "Epoch 1/20\n",
      "274/274 [==============================] - 68s 241ms/step - loss: 293.1081 - reconstruction_loss: 227.7772 - kl_loss: 2.4904\n",
      "Epoch 2/20\n",
      "274/274 [==============================] - 63s 230ms/step - loss: 193.6513 - reconstruction_loss: 184.7759 - kl_loss: 4.2984\n",
      "Epoch 3/20\n",
      "274/274 [==============================] - 63s 232ms/step - loss: 176.9014 - reconstruction_loss: 168.7466 - kl_loss: 5.8419\n",
      "Epoch 4/20\n",
      "274/274 [==============================] - 59s 215ms/step - loss: 169.3343 - reconstruction_loss: 162.3221 - kl_loss: 6.1031\n",
      "Epoch 5/20\n",
      "274/274 [==============================] - 62s 227ms/step - loss: 165.8592 - reconstruction_loss: 158.6072 - kl_loss: 6.2941\n",
      "Epoch 6/20\n",
      "274/274 [==============================] - 70s 254ms/step - loss: 163.3430 - reconstruction_loss: 155.7934 - kl_loss: 6.4859\n",
      "Epoch 7/20\n",
      "274/274 [==============================] - 75s 275ms/step - loss: 160.6365 - reconstruction_loss: 153.8882 - kl_loss: 6.5423\n",
      "Epoch 8/20\n",
      "274/274 [==============================] - 70s 257ms/step - loss: 159.2295 - reconstruction_loss: 152.4824 - kl_loss: 6.6100\n",
      "Epoch 9/20\n",
      "274/274 [==============================] - 68s 248ms/step - loss: 158.2921 - reconstruction_loss: 151.4276 - kl_loss: 6.6533\n",
      "Epoch 10/20\n",
      "274/274 [==============================] - 66s 241ms/step - loss: 157.4869 - reconstruction_loss: 150.7014 - kl_loss: 6.6975\n",
      "Epoch 11/20\n",
      "274/274 [==============================] - 64s 233ms/step - loss: 156.5291 - reconstruction_loss: 149.9553 - kl_loss: 6.7235\n",
      "Epoch 12/20\n",
      "274/274 [==============================] - 66s 241ms/step - loss: 155.9315 - reconstruction_loss: 149.3257 - kl_loss: 6.7240\n",
      "Epoch 13/20\n",
      "274/274 [==============================] - 67s 244ms/step - loss: 155.5114 - reconstruction_loss: 148.8271 - kl_loss: 6.7621\n",
      "Epoch 14/20\n",
      "274/274 [==============================] - 70s 254ms/step - loss: 155.0165 - reconstruction_loss: 148.4635 - kl_loss: 6.7388\n",
      "Epoch 15/20\n",
      "274/274 [==============================] - 64s 234ms/step - loss: 154.9924 - reconstruction_loss: 148.0740 - kl_loss: 6.7537\n",
      "Epoch 16/20\n",
      "274/274 [==============================] - 74s 269ms/step - loss: 154.3415 - reconstruction_loss: 147.6915 - kl_loss: 6.7506\n",
      "Epoch 17/20\n",
      "274/274 [==============================] - 85s 312ms/step - loss: 154.2491 - reconstruction_loss: 147.4604 - kl_loss: 6.7695\n",
      "Epoch 18/20\n",
      "274/274 [==============================] - 83s 302ms/step - loss: 153.9415 - reconstruction_loss: 147.0991 - kl_loss: 6.7741\n",
      "Epoch 19/20\n",
      "274/274 [==============================] - 81s 296ms/step - loss: 153.8794 - reconstruction_loss: 146.8981 - kl_loss: 6.7577\n",
      "Epoch 20/20\n",
      "274/274 [==============================] - 77s 281ms/step - loss: 153.1300 - reconstruction_loss: 146.5656 - kl_loss: 6.7539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb44706190>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(mnist_digits,\n",
    "      epochs = 20,\n",
    "      batch_size = 256)\n",
    "\n",
    "va.fit(mnist_digits,\n",
    "      epochs = 20,\n",
    "      batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import projection objects\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the latent points for each input data\n",
    "ae_mean = ae.encoder.predict(mnist_digits)\n",
    "va_mean, z_var, va_z = va.encoder.predict(mnist_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the latent point according to the t-SNE algorithm\n",
    "ae_tsne = TSNE().fit_transform(ae_mean)\n",
    "va_tsne = TSNE().fit_transform(va_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the latent point according to PCA and caluclate the principal axes\n",
    "pca_ae = PCA(n_components = 2).fit(ae_mean)\n",
    "ae_pca = pca_ae.transform(ae_mean)\n",
    "ae_vectors = (pca_ae.components_.T *3*np.sqrt(pca_ae.explained_variance_)).T\n",
    "ae_origin = np.mean(ae_mean, axis = 0)\n",
    "\n",
    "pca_va = PCA(n_components = 2).fit(va_mean)\n",
    "va_pca = pca_va.transform(va_mean)\n",
    "va_vectors = (pca_va.components_.T *3*np.sqrt(pca_va.explained_variance_)).T\n",
    "va_origin = np.mean(va_mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gui:s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample scatter plot\n",
    "This visualization shows a 2D representation of the latent space and where each of the input point has been projected. This projection is done previously and is usually a PCA or t-SNE. Note that only one of the figures can work interactily at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplescattergui import SampleScatterGUI\n",
    "from latentplanegui import LatentPlaneGUI\n",
    "from latentinterpolationmosaic import LatentInterpolationMosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Scatter GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<samplescattergui.SampleScatterGUI at 0x1bb43226ee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA/t-SNE of the autoencoder\n",
    "#SampleScatterGUI(ae_pca, mnist_labels, mnist_digits)\n",
    "SampleScatterGUI(ae_tsne, mnist_labels, mnist_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<samplescattergui.SampleScatterGUI at 0x1bb48f1a2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA/t-SNE of the Variational Autoencoder\n",
    "#SampleScatterGUI(va_pca, mnist_labels, mnist_digits)\n",
    "SampleScatterGUI(va_tsne, mnist_labels, mnist_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Plane GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentplanegui.LatentPlaneGUI at 0x1bb48faaf70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentPlaneGUI(ae.decoder,latent_vectors = ae_vectors, latent_origin = ae_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentplanegui.LatentPlaneGUI at 0x2db31a76310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentPlaneGUI(va.decoder,latent_vectors = va_vectors, latent_origin = va_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Interpolation Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentinterpolationmosaic.LatentInterpolationMosaic at 0x1bb4a8d0730>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = [30,400,1203]\n",
    "LatentInterpolationMosaic(ae.encoder,\n",
    "                          ae.decoder,\n",
    "                          mnist_digits,\n",
    "                          indeces,\n",
    "                          num_row = 15,\n",
    "                          num_col = 15,\n",
    "                          variational = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentinterpolationmosaic.LatentInterpolationMosaic at 0x1bb4cbd47f0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentInterpolationMosaic(va.encoder,\n",
    "                          va.decoder,\n",
    "                          mnist_digits,\n",
    "                          indeces,\n",
    "                          num_row = 15,\n",
    "                          num_col = 15,\n",
    "                          variational = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
