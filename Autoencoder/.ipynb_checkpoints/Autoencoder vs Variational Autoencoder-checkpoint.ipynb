{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from normalsamplinglayer import NormalSamplingLayer\n",
    "import numpy.random as rnd\n",
    "\n",
    "from variationalautoencoder import VariationalAutoencoder\n",
    "from autoencoder import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "latent_dim = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup data\n",
    "Load and preprocess data\n",
    "\n",
    "After this section we will have the two variables *mnist_digits* and *mnist_labels*. They are both numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "mnist_labels = np.concatenate([y_train, y_test], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup autoencoders\n",
    "Define the encoder and decoder which are then the defining features of our variational encoder and decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the encoders and decoders. The code is simply repeated for the autoencoder and the variational autoencoder. The only difference is that there is a parallell layer in the encoder for the variational autoencoder which defindes the variacnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder encoder\n",
    "encoder_input = keras.Input(shape = mnist_digits[0].shape)\n",
    "net = encoder_input\n",
    "net = keras.layers.Conv2D(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2D(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Flatten()(net)\n",
    "net = keras.layers.Dense(16, activation = 'relu')(net)\n",
    "z = keras.layers.Dense(latent_dim, name = 'z_mean')(net)\n",
    "encoder_auto = keras.Model(encoder_input, z, name = 'encoder')\n",
    "\n",
    "# Variational autoencoder encoder\n",
    "encoder_input = keras.Input(shape = mnist_digits[0].shape)\n",
    "net = encoder_input\n",
    "net = keras.layers.Conv2D(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2D(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Flatten()(net)\n",
    "net = keras.layers.Dense(16, activation = 'relu')(net)\n",
    "z_mean = keras.layers.Dense(latent_dim, name = 'z_mean')(net)\n",
    "z_log_var = keras.layers.Dense(latent_dim, name = 'z_log_var')(net)\n",
    "z = NormalSamplingLayer()([z_mean, z_log_var])\n",
    "encoder_var = keras.Model(encoder_input, [z_mean, z_log_var, z], name = 'encoder')\n",
    "\n",
    "# Autoencoder decoder\n",
    "decoder_input = keras.Input(shape = (latent_dim,))\n",
    "net = decoder_input\n",
    "net = keras.layers.Dense(7*7*64, activation = \"relu\")(net)\n",
    "net = keras.layers.Reshape((7,7,64))(net)\n",
    "net = keras.layers.Conv2DTranspose(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(1,3, activation = 'sigmoid', padding = 'same')(net)\n",
    "decoder_output = net\n",
    "decoder_auto = keras.Model(decoder_input, decoder_output, name = 'decoder')\n",
    "\n",
    "# Variational autoencoder decoder\n",
    "decoder_input = keras.Input(shape = (latent_dim,))\n",
    "net = decoder_input\n",
    "net = keras.layers.Dense(7*7*64, activation = \"relu\")(net)\n",
    "net = keras.layers.Reshape((7,7,64))(net)\n",
    "net = keras.layers.Conv2DTranspose(64,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(32,3, activation = 'relu', strides = 2, padding = 'same')(net)\n",
    "net = keras.layers.Conv2DTranspose(1,3, activation = 'sigmoid', padding = 'same')(net)\n",
    "decoder_output = net\n",
    "decoder_var = keras.Model(decoder_input, decoder_output, name = 'decoder')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the autoencoder instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = Autoencoder(encoder_auto, decoder_auto)\n",
    "va = VariationalAutoencoder(encoder_var, decoder_var)\n",
    "ae.compile(optimizer=keras.optimizers.Adam())\n",
    "va.compile(optimizer=keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "274/274 [==============================] - 53s 191ms/step - Loss: 275.6510\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - 53s 195ms/step - Loss: 146.6383\n",
      "Epoch 1/2\n",
      "274/274 [==============================] - 58s 207ms/step - loss: 303.9152 - reconstruction_loss: 239.2811 - kl_loss: 0.003118s - loss: 33\n",
      "Epoch 2/2\n",
      "274/274 [==============================] - 58s 214ms/step - loss: 207.2850 - reconstruction_loss: 207.1813 - kl_loss: 0.0031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2db25f32e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae.fit(mnist_digits,\n",
    "      epochs = 2,\n",
    "      batch_size = 256)\n",
    "\n",
    "va.fit(mnist_digits,\n",
    "      epochs = 2,\n",
    "      batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project the latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import projection objects\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the latent points for each input data\n",
    "ae_mean = ae.encoder.predict(mnist_digits)\n",
    "va_mean, z_var, va_z = va.encoder.predict(mnist_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the latent point according to the t-SNE algorithm\n",
    "ae_tsne = TSNE().fit_transform(ae_mean)\n",
    "va_tsne = TSNE().fit_transform(va_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project the latent point according to PCA and caluclate the principal axes\n",
    "pca_ae = PCA(n_components = 2).fit(ae_mean)\n",
    "ae_pca = pca_ae.transform(ae_mean)\n",
    "ae_vectors = (pca_ae.components_.T *3*np.sqrt(pca_ae.explained_variance_)).T\n",
    "ae_origin = np.mean(ae_mean, axis = 0)\n",
    "\n",
    "pca_va = PCA(n_components = 2).fit(va_mean)\n",
    "va_pca = pca_va.transform(va_mean)\n",
    "va_vectors = (pca_va.components_.T *3*np.sqrt(pca_va.explained_variance_)).T\n",
    "va_origin = np.mean(va_mean, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Gui:s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample scatter plot\n",
    "This visualization shows a 2D representation of the latent space and where each of the input point has been projected. This projection is done previously and is usually a PCA or t-SNE. Note that only one of the figures can work interactily at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplescattergui import SampleScatterGUI\n",
    "from latentplanegui import LatentPlaneGUI\n",
    "from latentinterpolationmosaic import LatentInterpolationMosaic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Scatter GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<samplescattergui.SampleScatterGUI at 0x2db2b6bfb20>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA/t-SNE of the autoencoder\n",
    "SampleScatterGUI(ae_pca, mnist_labels, mnist_digits)\n",
    "#SampleScatterGUI(ae_tsne, mnist_labels, mnist_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<samplescattergui.SampleScatterGUI at 0x2db31529190>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PCA/t-SNE of the Variational Autoencoder\n",
    "SampleScatterGUI(va_pca, mnist_labels, mnist_digits)\n",
    "#SampleScatterGUI(va_tsne, mnist_labels, mnist_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Plane GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentplanegui.LatentPlaneGUI at 0x2db31a2e6a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentPlaneGUI(ae.decoder,latent_vectors = ae_vectors, latent_origin = ae_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentplanegui.LatentPlaneGUI at 0x2db31a76310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentPlaneGUI(va.decoder,latent_vectors = va_vectors, latent_origin = va_origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Interpolation Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentinterpolationmosaic.LatentInterpolationMosaic at 0x2db321f8070>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = [0,3,4]\n",
    "LatentInterpolationMosaic(ae.encoder,\n",
    "                          ae.decoder,\n",
    "                          mnist_digits,\n",
    "                          indeces,\n",
    "                          num_row = 10,\n",
    "                          num_col = 5,\n",
    "                          variational = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<latentinterpolationmosaic.LatentInterpolationMosaic at 0x2db321c9550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LatentInterpolationMosaic(va.encoder,\n",
    "                          va.decoder,\n",
    "                          mnist_digits,\n",
    "                          indeces,\n",
    "                          num_row = 10,\n",
    "                          num_col = 5,\n",
    "                          variational = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
