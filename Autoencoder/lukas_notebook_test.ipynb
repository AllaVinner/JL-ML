{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt \r\n",
    "import tensorflow as tf \r\n",
    "\r\n",
    "import sklearn\r\n",
    "from tensorflow.keras import layers, losses, regularizers\r\n",
    "from tensorflow.keras.datasets import mnist\r\n",
    "from tensorflow.keras.models import Model\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "(x_train, _), (x_test, y_test) = mnist.load_data()\r\n",
    "n = 4\r\n",
    "\r\n",
    "# Normalize pixel values\r\n",
    "x_train = x_train.astype('float32') / 255.\r\n",
    "x_test = x_test.astype('float32') / 255.\r\n",
    "\r\n",
    "print(\"Input dimensions:\", x_train[0].size)\r\n",
    "\r\n",
    "plt.figure(figsize=(4, 4))\r\n",
    "\r\n",
    "# Plot 4x4 grid of training samples\r\n",
    "for i in range(1, n*n+1):\r\n",
    "    ax = plt.subplot(n, n, i)\r\n",
    "    plt.imshow(x_train[i])\r\n",
    "    ax.get_yaxis().set_visible(False)\r\n",
    "    ax.get_xaxis().set_visible(False)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sparse constraint\n",
    "\n",
    "Forcing a layer's average activation to be close to a constraint\n",
    "\n",
    "Why do we want to do this?\n",
    "Try to get the network to not learn the principal components of the data?\n",
    "Get the weights to fire less?\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Define autoencoder\r\n",
    "\r\n",
    "latent_dim = 32\r\n",
    "\r\n",
    "class Autoencoder(Model):\r\n",
    "    # Constructor\r\n",
    "    def __init__(self, latent_dim):\r\n",
    "        super(Autoencoder, self).__init__()\r\n",
    "        self.latent_dim = latent_dim\r\n",
    "        self.encoder = tf.keras.Sequential([\r\n",
    "            # Converts tensor input to vector? (28, 28) -> (784)\r\n",
    "            layers.Flatten(),\r\n",
    "            layers.Dense(latent_dim, activation='relu', activity_regularizer=regularizers.l1(10e-5)),\r\n",
    "        ])\r\n",
    "        self.decoder = tf.keras.Sequential([\r\n",
    "            # Output 784 pixel values between [0, 1]\r\n",
    "            layers.Dense(784, activation='sigmoid'),\r\n",
    "            layers.Reshape((28, 28)),\r\n",
    "        ])\r\n",
    "    \r\n",
    "    def call(self, x):\r\n",
    "        encoded = self.encoder(x)\r\n",
    "        decoded = self.decoder(encoded)\r\n",
    "        return decoded\r\n",
    "\r\n",
    "autoencoder = Autoencoder(latent_dim)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# \"Configures the model for training\", we specify loss, metrics, etc.\r\n",
    "\r\n",
    "# Binary cross entropy cause pixel values are [0, 1]?\r\n",
    "autoencoder.compile(optimizer='adam', loss = losses.BinaryCrossentropy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training\r\n",
    "# epochs: nr passes over the dataset\r\n",
    "history = autoencoder.fit(x_train, x_train,\r\n",
    "                epochs=50,\r\n",
    "                batch_size=256,\r\n",
    "                shuffle=True,\r\n",
    "                validation_data=(x_test, x_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "autoencoder.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.plot(history.history['loss'])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Evaluate of test set\r\n",
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\r\n",
    "print(encoded_imgs.shape)\r\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = 10\r\n",
    "plt.figure(figsize=(20, 4)) # Specifies window width / height\r\n",
    "for i in range(n):\r\n",
    "    # original\r\n",
    "    ax = plt.subplot(2, n, i + 1)\r\n",
    "    plt.imshow(x_test[i])\r\n",
    "    plt.title(\"original\")\r\n",
    "    # plt.gray()\r\n",
    "    ax.get_xaxis().set_visible(False)\r\n",
    "    ax.get_yaxis().set_visible(False)\r\n",
    "\r\n",
    "    # reconstructed\r\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\r\n",
    "    plt.imshow(decoded_imgs[i])\r\n",
    "    plt.title(\"reconstructed\")\r\n",
    "    # plt.gray()\r\n",
    "    ax.get_xaxis().set_visible(False)\r\n",
    "    ax.get_yaxis().set_visible(False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# linear interpolation test\r\n",
    "img_1 = x_test[2].reshape(1, x_test[0].size) # resize to single element tensor\r\n",
    "img_2 = x_test[3].reshape(1, x_test[1].size)\r\n",
    "\r\n",
    "# image encodings\r\n",
    "encoded_img_1 = autoencoder.encoder(img_1).numpy() \r\n",
    "encoded_img_2 = autoencoder.encoder(img_2).numpy()\r\n",
    "nbr_points = 12\r\n",
    "\r\n",
    "t = np.linspace(1, 0, num=nbr_points)\r\n",
    "\r\n",
    "encoded_interpols = np.zeros([nbr_points, encoded_img_1.size])\r\n",
    "\r\n",
    "for i in range(nbr_points):\r\n",
    "    encoded_interpols[i] = t[i] * encoded_img_1 + (1-t[i]) * encoded_img_2\r\n",
    "\r\n",
    "print(encoded_interpols.shape)\r\n",
    "\r\n",
    "decoded_interpols = autoencoder.decoder(encoded_interpols).numpy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot interpolations\r\n",
    "\r\n",
    "plt.figure(figsize=(20, 4))\r\n",
    "for i in range(nbr_points):\r\n",
    "    ax = plt.subplot(1, nbr_points, i+1)\r\n",
    "    plt.imshow(decoded_interpols[i])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "random_latent = np.random.rand(latent_dim)*37\r\n",
    "random_latent = random_latent.reshape(1, latent_dim)\r\n",
    "random_decoded = autoencoder.decoder(random_latent)\r\n",
    "\r\n",
    "plt.figure()\r\n",
    "plt.imshow(random_decoded.numpy()[0])\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# T-SNE test\r\n",
    "\r\n",
    "from sklearn.manifold import TSNE\r\n",
    "\r\n",
    "embeddings_tsne = TSNE(n_components=2).fit_transform(encoded_imgs)\r\n",
    "interpols_tsne = TSNE(n_components=2).fit_transform(encoded_interpols)\r\n",
    "\r\n",
    "print(embeddings_tsne.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Plot projected embeddings\r\n",
    "fig, ax = plt.subplots(figsize=(8,8))\r\n",
    "\r\n",
    "scatter = ax.scatter(embeddings_tsne[:,0], embeddings_tsne[:,1], c = y_test.astype('float32'), cmap='tab10')\r\n",
    "\r\n",
    "# Plot interpolated points, weird structure caused by TSNE?\r\n",
    "ax.scatter(interpols_tsne[:,0], interpols_tsne[:,1], marker=\"x\", color='000000', linewidths=6)\r\n",
    "\r\n",
    "legend1 = ax.legend(*scatter.legend_elements(),\r\n",
    "                    loc=\"upper left\", title=\"Classes\")\r\n",
    "\r\n",
    "ax.add_artist(legend1)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from latentinterpolationmosaic import LatentInterpolationMosaic\r\n",
    "print(x_test.shape)\r\n",
    "\r\n",
    "x_test = tf.expand_dims(x_test, axis=3)\r\n",
    "\r\n",
    "print(x_test.shape)\r\n",
    "mosaic = LatentInterpolationMosaic(autoencoder.encoder, autoencoder.decoder, x_test, [1, 2, 3])"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd593813f0e920a894f9bede9157c42ea32ce77eaa35990e17a2847ab973ef24"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('JL-ML': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}